{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <center>\n",
    "    <h1>Bank Loan Default Case</h1>\n",
    "</center>\n",
    "\n",
    "**Background:** \n",
    "The loan default dataset has 8 variables and 850 records, each record being loan default status for each customer. Each Applicant was rated as “Defaulted” or “Not-Defaulted”. New applicants for loan application can also be evaluated on these 8 predictor variables and classified as a default or non-default based on predictor variables.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from  matplotlib import pyplot \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.datasets import make_classification\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('F:/Rittal Docs/edwisor.com/02.Portfolio/02.Project-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"bank-loan.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ univariate analysis and bivariate analysis ##########################\n",
    "# analysis for single variable in the dataset and relation between 2 variables.\n",
    "sns.distplot(df[\"age\"], kde = True , bins = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df[\"income\"], kde = True , bins = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df[\"othdebt\"], kde = True , bins = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df[\"creddebt\"], kde = True , bins = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df[\"debtinc\"], kde = True , bins = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot( x = \"default\" , data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot( x = \"ed\" , data = df, hue = \"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize = (15,10))\n",
    "sns.countplot( x = \"income\" , data = df, hue = \"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the relationship between all numeric variable using pair plot\n",
    "plt.figure(figsize=(14,5))\n",
    "sns.pairplot(df[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Analysis\n",
    "- Bivariate Analysis - Numeric(TTest)/ Categorical(Chisquare)\n",
    "- Bivariate Analysis - Visualization\n",
    "- Variable Reduction - Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## performing the independent t test on numerical variables\n",
    "\n",
    "tstats_df = pd.DataFrame()\n",
    "numeric_var_names=df\n",
    "\n",
    "for eachvariable in numeric_var_names:\n",
    "    tstats = stats.ttest_ind(df.loc[df[\"default\"] == 1,eachvariable],df.loc[df[\"default\"] == 0, eachvariable],equal_var=False)\n",
    "    temp = pd.DataFrame([eachvariable, tstats[0], tstats[1]]).T\n",
    "    temp.columns = ['Variable Name', 'T-Statistic', 'P-Value']\n",
    "    tstats_df = pd.concat([tstats_df, temp], axis=0, ignore_index=True)\n",
    "    \n",
    "tstats_df =  tstats_df.sort_values(by = \"P-Value\").reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P <0.05 therefore we reject null hypo.\n",
    "Null hypo = \n",
    "<br>\n",
    "Alternate hype = Bothe means from different distributions(which is that the population means are not equal)\n",
    "<br>\n",
    "P<0.05 ARE for :\n",
    "Age=true,Address(P: 0.00000207201)=true,creddebt(P: 0.000000390256)=true,etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-Variate Analysis-Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BivariateAnalysisPlot(segment_by):\n",
    "    \"\"\"A funtion to analyze the impact of features on the target variable\"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(ncols=1,figsize = (10,8))\n",
    "    \n",
    "    #boxplot\n",
    "    sns.boxplot(x = 'default', y = segment_by, data=df)\n",
    "    plt.title(\"Box plot of \"+segment_by)\n",
    "    \n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BivariateAnalysisPlot(\"age\")\n",
    "#For default 0 the average age is 35, default 1 is 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BivariateAnalysisPlot(\"ed\")\n",
    "#Both Same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BivariateAnalysisPlot(\"employ\")\n",
    "##For default 0 the avrage eploy is 8, default 1 is 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BivariateAnalysisPlot(\"address\")\n",
    "#For default 0 its 8, for default 1 its 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BivariateAnalysisPlot(\"income\")\n",
    "#For default 0 its 35, for default 1 its 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BivariateAnalysisPlot(\"debtinc\")\n",
    "#For default 0 its 8, for default 1 its 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BivariateAnalysisPlot(\"creddebt\")\n",
    "#For default 0 its 0.5, for default 1 its 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BivariateAnalysisPlot(\"othdebt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Variable Reduction - Multicollinearity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patsy import dmatrices\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = \"+\".join(df.columns.difference([\"default\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform vif\n",
    "\n",
    "a, b = dmatrices(formula_like= 'default ~ ' + features,data=df,return_type=\"dataframe\")\n",
    "vif = pd.DataFrame()\n",
    "\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(b.values, i) for i in range(b.shape[1])]\n",
    "vif[\"Features\"] = b.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "----\n",
    "\n",
    "- There are 850 observations and 9 features in the data set\n",
    "- All 9 features are numerical in nature\n",
    "- Out of 850 customers data, 700 are existing customers and 150 are new customers\n",
    "- In the 700 existing customers, 517 customers are tagged as non defaulters and remaining 183 are tagged as defaulters\n",
    "- The data is highly imbalanced\n",
    "- From VIF check, found out that the correlation between the variables is within the acceptable limits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "1. Age-Age of each customer                      Numerical\n",
    "2. Education-Education categories                Categorical\n",
    "3. Employment-Employment status -                Numerical\n",
    "    Corresponds to job\n",
    "    status and being\n",
    "    converted to numeric\n",
    "    format\n",
    "4. Address-Geographic area -                     Numerical\n",
    "    Converted to numeric\n",
    "    values\n",
    "5  Income-Gross Income of each                   Numerical\n",
    "    customer\n",
    "6. debtinc-Individual’s debt                     Numerical\n",
    "    payment to his or her\n",
    "    gross income\n",
    "7. creddebt debt-to-credit ratio is a            Numerical\n",
    "    measurement of how\n",
    "    much you owe your\n",
    "    creditors as a\n",
    "    percentage of your\n",
    "    available credit (credit\n",
    "    limits)\n",
    "8. othdebt-Any other debts                       Numerical\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null values present=====> 150 values are missing\n",
    "# [df[\"default\"].isna()]\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing value analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe with missing percentage\n",
    "missing_val = pd.DataFrame(df.isnull().sum())\n",
    "\n",
    "#Reset index\n",
    "missing_val = missing_val.reset_index()\n",
    "\n",
    "#Rename variable\n",
    "missing_val = missing_val.rename(columns = {'index': 'Variables', 0: 'Missing_percentage'})\n",
    "\n",
    "#Calculate percentage\n",
    "missing_val['Missing_percentage'] = (missing_val['Missing_percentage']/len(df))*100\n",
    "\n",
    "#descending order\n",
    "missing_val = missing_val.sort_values('Missing_percentage', ascending = False).reset_index(drop = True)\n",
    "\n",
    "\n",
    "#save output results \n",
    "missing_val.to_csv(\"Mising_perc_python.csv\", index = False)\n",
    "missing_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar Graph for missing values\n",
    "\n",
    "sns.barplot( x='Variables', y='Missing_percentage', data = missing_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.isnull(), yticklabels = False, cmap = \"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sort_values( ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute with median -unsure because cannot fill in missing values for them\n",
    "# df['default'] = df['default'].fillna(df['default'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.default = df.default.fillna(2)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.default = df.default.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot boxplot to visualize Outliers\n",
    "%matplotlib inline  \n",
    "l = df.columns.values\n",
    "number_of_columns=9\n",
    "number_of_rows = len(l)-1/number_of_columns\n",
    "plt.figure(figsize=(number_of_columns,5*number_of_rows))\n",
    "for i in range(0,len(l)):\n",
    "    plt.subplot(number_of_rows + 1,number_of_columns,i+1)\n",
    "    sns.set_style('whitegrid')\n",
    "    sns.boxplot(df[l[i]],color='red',orient='v')\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To check distribution-Skewness\n",
    "plt.figure(figsize=(2*number_of_columns,5*number_of_rows))\n",
    "for i in range(0,len(l)):\n",
    "    plt.subplot(number_of_rows + 1,number_of_columns,i+1)\n",
    "    sns.distplot(df[l[i]],kde=True) \n",
    "#All independent variables are right skewed/positively skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.boxplot(df['income']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier treatment\n",
    "#clip_upper() is used to trim values at specified input threshold. We use this function to trim all the values above the threshold of the input value to the specified input value.\n",
    "#quantile() function return values at the given quantile over requested axis, a numpy.percentile.\n",
    "#Trim as in it deletes the outlier and replaces it with the upper limit value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_capping(x):\n",
    "    \"\"\"A funtion to remove and replace the outliers for numerical columns\"\"\"\n",
    "    x = x.clip_upper(x.quantile(0.95))\n",
    "    \n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outlier treatment\n",
    "df = df.apply(lambda x: outlier_capping(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tm = df.groupby(\"default\").mean()\n",
    "# tm\n",
    "# df.groupby(\"default\")[\"employ\"].describe()\n",
    "# df.groupby(\"default\")[\"age\"].describe()\n",
    "# df.groupby(\"default\")[\"ed\"].describe()\n",
    "df.groupby(\"default\")[\"address\"].describe()\n",
    "# df.groupby(\"default\")[\"income\"].describe() \n",
    "# df.groupby(\"default\")[\"debtinc\"].describe()\n",
    "# df.groupby(\"default\")[\"creddebt\"].describe()\n",
    "# df.groupby(\"default\")[\"othdebt\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_corr = df\n",
    "#Set the width and height of the plot\n",
    "f, ax = plt.subplots(figsize=(12, 7))\n",
    "#Set the width and height of the plot\n",
    "f, ax = plt.subplots(figsize=(12, 7))\n",
    "#Generate correlation matrix\n",
    "corr = df_corr.corr()\n",
    "#Plot using seaborn library\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap='Blues',\n",
    "            square=True,annot= True, ax=ax)\n",
    "# Dark shades represents positive correlation while lighter shades represents negative correlation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default correlation matrix\n",
    "k = 8 #number of variables for heatmap\n",
    "cols = df.corr().nlargest(k, 'default')['default'].index\n",
    "cm = df[cols].corr()\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(cm, annot=True, cmap = 'viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " As we can observe in plot, none of variables are identical to each other, it means that these variables are not highly correlated variables,  so we have to consider all variables for model developement as all variables are important now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square test of independence-for select categorical variables\n",
    "\n",
    "Save categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, variables__ 'ed' __and__ 'default'__ are only categorical variables, so lets convert them to factor dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting 'ed' and 'default' into categorical type\n",
    "df['ed'] = pd.Categorical(df['ed'])\n",
    "print(df.ed.dtype)\n",
    "\n",
    "df['default'] = pd.Categorical(df['default'])\n",
    "print(df.default.dtype)\n",
    "\n",
    "#print(marketing_train[[i]])\n",
    "#marketing_train.iloc[:,i]=marketing_train.iloc[:,i].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_names = [\"ed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency  # for chi-sqr test and comtingency table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop for chi square values   # p = 0.05,  if p < 0.05, Reject Null hyp., Consider that var\n",
    "\n",
    "from scipy.stats import chi2_contingency  # for chi-sqr test and comtingency table\n",
    "\n",
    "for i in cat_names:\n",
    "    print(i)\n",
    "    chi2, p, dof, ex = chi2_contingency(pd.crosstab(df['default'], df[i]))\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " As we can, see , p Value of cat var (ed) is < 0.05 , It means We reject Null Hypothesis saying that these two variables are important to each other and we cannot drop any one of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling \n",
    " scale the imporant features in measurable units\n",
    " 1) Scaling by Normalization\n",
    "or_2) Scaling by Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most data sets, we will have features with high varying range, units and magnitudes. Features with greater magnitudes will carry a greater value than those with low magnitudes. To nullify this effect, feature scaling is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check Normality by Histogram Before Normalization / Standerdization\n",
    "\n",
    "%matplotlib inline  \n",
    "plt.hist(df['age'], bins='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifying  it again\n",
    "    \n",
    "%matplotlib inline  \n",
    "plt.hist(df['income'], bins='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Since we can see that , data is not normallaly distributed , Hence go for **Normalization** 1st instead of Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnames = ['age', 'employ', 'address', 'income', 'debtinc', 'creddebt', 'othdebt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nomalisation\n",
    "\n",
    "for i in cnames:\n",
    "    print(i)\n",
    "    df[i] = (df[i] - min(df[i]))/(max(df[i]) - min(df[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "features = df.columns\n",
    "importances = best_rf_clf.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### selecting all missing values from dataset and we will predict those default case with best accurate \n",
    "\n",
    "train = df.loc[df['default'] != 2]\n",
    "print(train.head())\n",
    "print(train.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.default.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.loc[df.default == 2]\n",
    "test = test.iloc[:, 0:8]\n",
    "print(test.head(2))\n",
    "print(test.tail(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['default'], axis=1)\n",
    "y = train['default']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test,y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################### Logistic Regression ####################################################\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg =LogisticRegression(penalty='l2', C=0.1)\n",
    "logreg.fit(X_train,y_train)\n",
    "#predict new test cases\n",
    "Log_Predictions = logreg.predict(X_test)\n",
    "print(logreg.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_space = np.array([0.0001, 0.001, 0.1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C' : C_space}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_logis_tuning = GridSearchCV(logreg, param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_logis_tuning.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tuned Logistic Regression Parameters: {}\".format(clf_logis_tuning.best_params_)) \n",
    "print(\"Best score is {}\".format(clf_logis_tuning.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Logistic Regression, we achieved a training set accuracy of ~79% (in terms of training set accuracy alone.)\n",
    "\n",
    "Next, the model will be fit with the best parameter of C and then it will be used to predict the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Log_Predictions = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_logreg_ba = logreg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, Log_Predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, Log_Predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_lg, recall_lg, thresholds_lg = precision_recall_curve(y_test, p_logreg_ba[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_lg, tpr_lg, thresholds_lg = roc_curve(y_test, p_logreg_ba[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build confusion matrix\n",
    "\n",
    "CM = pd.crosstab(y_test,Log_Predictions)\n",
    "\n",
    "#let us save TP, TN, FP, FN\n",
    "TN = CM.iloc[0,0]\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FP = CM.iloc[0,1]\n",
    "\n",
    "#check accuracy of model\n",
    "#accuracy_score(ytest, y_preds)*100\n",
    "print(((TP+TN)*100)/(TP+TN+FP+FN))\n",
    "\n",
    "#False Negative rate \n",
    "print((FN*100)/(FN+TP))\n",
    "\n",
    "print(\"Defaulted\", sum(Log_Predictions!=0))\n",
    "print(\"Non-defaulted \", sum(Log_Predictions==0))\n",
    "CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC curve and AUC\n",
    "prob=logreg.predict_proba(X_test)\n",
    "# print(prob)\n",
    "prob=prob[:,0]\n",
    "auc=roc_auc_score(y_test,prob)\n",
    "print(auc)\n",
    "fpr,tpr,thresh=roc_curve(y_test,prob)\n",
    "plt.plot([0,1],[1,0],linestyle='--')\n",
    "plt.plot(fpr,tpr,marker='.',color='red',label=\"Logistic regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################### Decision Tree #####################################\n",
    "from sklearn import tree\n",
    "C50_model = tree.DecisionTreeClassifier(criterion='entropy').fit(X_train, y_train)\n",
    "\n",
    "#predict new test cases\n",
    "C50_Predictions = C50_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  plotting decision tree\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "dot_data = StringIO()\n",
    "export_graphviz(C50_model, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build confusion matrix\n",
    "# from sklearn.metrics import confusion_matrix \n",
    "# CM = confusion_matrix(y_test, y_pred)\n",
    "CM = pd.crosstab(y_test, C50_Predictions)\n",
    "\n",
    "#let us save TP, TN, FP, FN\n",
    "TN = CM.iloc[0,0]\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FP = CM.iloc[0,1]\n",
    "\n",
    "#check accuracy of model\n",
    "#accuracy_score(y_test, y_pred)*100\n",
    "print(((TP+TN)*100)/(TP+TN+FP+FN))\n",
    "\n",
    "#False Negative rate \n",
    "print((FN*100)/(FN+TP))\n",
    "\n",
    "print(\"Defaulted\", sum(C50_Predictions!=0))\n",
    "print(\"Non-defaulted \", sum(C50_Predictions==0))\n",
    "#Results\n",
    "CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, C50_Predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_predict1 =C50_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_dc, recall_dc, thresholds_dc = precision_recall_curve(y_test,dt_predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_dc, tpr_dc, thresholds_dc = roc_curve(y_test,C50_Predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC curve and AUC\n",
    "prob=C50_model.predict_proba(X_test)\n",
    "# print(prob)\n",
    "prob=prob[:,0]\n",
    "auc=roc_auc_score(y_test,prob)\n",
    "print(auc)\n",
    "fpr,tpr,thresh=roc_curve(y_test,prob)\n",
    "plt.plot([0,1],[1,0],linestyle='--')\n",
    "plt.plot(fpr,tpr,marker='.',color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################### Random Forest #####################################\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF_model = RandomForestClassifier(n_estimators = 200).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_Predictions = RF_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score = cross_val_score(RF_model, X_train, y_train, cv = 5)\n",
    "print(\"Average 5-fold CV Score: {}\".format(np.mean(cv_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score = cross_val_score(RF_model, X_train, y_train, cv = 5, scoring = 'roc_auc')\n",
    "print(\"Average 5-fold CV Score using ROC_AUC: {}\".format(np.mean(cv_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, RF_Predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_space = np.array([5, 6, 10, 12, 15, 50, 100, 200, 500])\n",
    "criterion_vals = ['gini', 'entropy']\n",
    "max_features_vals = ['auto', 'sqrt', 'log2']\n",
    "min_samples_leaf_sp = [1, 5, 10, 25, 50]\n",
    "bootstrap_sp = [True, False]\n",
    "\n",
    "\n",
    "param_grid = {'n_estimators': n_space, 'criterion' : criterion_vals, \n",
    "              'max_features':max_features_vals, 'min_samples_leaf': min_samples_leaf_sp, \n",
    "              'bootstrap': bootstrap_sp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf_tuning = GridSearchCV(RF_model, param_grid, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf_tuning.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tuned RF Parameters: {}\".format(rf_clf_tuning.best_params_)) \n",
    "print(\"Best score is {}\".format(rf_clf_tuning.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_clf = RandomForestClassifier(criterion = 'gini', bootstrap = True, \n",
    "                                     max_features = 'log2', min_samples_leaf = 5, n_estimators = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_best_rf_preds = best_rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score = cross_val_score(best_rf_clf, X_train, y_train, cv = 5)\n",
    "print(\"Average 5-fold CV Score: {}\".format(np.mean(cv_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_best_rf_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_best_proba = best_rf_clf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test, y_best_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, (y_best_proba > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_rf, recall_rf, thresholds_rf = precision_recall_curve(y_test, y_best_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build confusion matrix\n",
    "# from sklearn.metrics import confusion_matrix \n",
    "# CM = confusion_matrix(y_test, y_pred)\n",
    "CM = pd.crosstab(y_test, y_best_rf_preds)\n",
    "\n",
    "#let us save TP, TN, FP, FN\n",
    "TN = CM.iloc[0,0]\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FP = CM.iloc[0,1]\n",
    "\n",
    "#check accuracy of model\n",
    "#accuracy_score(y_test, y_pred)*100\n",
    "print(((TP+TN)*100)/(TP+TN+FP+FN))\n",
    "\n",
    "#False Negative rate \n",
    "print((FN*100)/(FN+TP))\n",
    "\n",
    "print(\"Defaulted\", sum(y_best_rf_preds!=0))\n",
    "print(\"Non-defaulted \", sum(y_best_rf_preds==0))\n",
    "CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC curve and AUC\n",
    "prob=best_rf_clf.predict_proba(X_test)\n",
    "# print(prob)\n",
    "prob=prob[:,0]\n",
    "auc=roc_auc_score(y_test,prob)\n",
    "print(auc)\n",
    "fpr,tpr,thresh=roc_curve(y_test,prob)\n",
    "plt.plot([0,1],[1,0],linestyle='--')\n",
    "plt.plot(fpr,tpr,marker='.',color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################### Gradient Boosting Algorithm #####################################\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = GradientBoostingClassifier(n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_xgb = clf_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_predict_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators':range(20,81,10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb_tuning = GridSearchCV(clf_xgb, param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb_tuning.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tuned Gradient Boosting Parameters: {}\".format(clf_xgb_tuning.best_params_)) \n",
    "print(\"Best score is {}\".format(clf_xgb_tuning.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb_best = GradientBoostingClassifier(n_estimators=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_xgb_best = clf_xgb_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_predict_xgb_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_xgb1 = clf_xgb_best.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_predict_xgb_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_xgb, recall_xgb, thresholds_xgb = precision_recall_curve(y_test, y_predict_xgb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_xgb, tpr_xgb, thresholds_xgb = roc_curve(y_test, y_predict_xgb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#build confusion matrix\n",
    "\n",
    "CM = pd.crosstab(y_test, y_predict_xgb_best)\n",
    "\n",
    "#let us save TP, TN, FP, FN\n",
    "TN = CM.iloc[0,0]\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FP = CM.iloc[0,1]\n",
    "\n",
    "#check accuracy of model\n",
    "#accuracy_score(ytest, dt_pred)*100\n",
    "print(((TP+TN)*100)/(TP+TN+FP+FN))\n",
    "\n",
    "#False Negative rate \n",
    "print((FN*100)/(FN+TP))\n",
    "\n",
    "print(\"Defaulted\", sum(y_predict_xgb_best!=0))\n",
    "print(\"Non-defaulted \", sum(y_predict_xgb_best==0))\n",
    "CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC curve and AUC\n",
    "prob=clf_xgb.predict_proba(X_test)\n",
    "# print(prob)\n",
    "prob=prob[:,0]\n",
    "auc=roc_auc_score(y_test,prob)\n",
    "print(auc)\n",
    "fpr,tpr,thresh=roc_curve(y_test,prob)\n",
    "plt.plot([0,1],[1,0],linestyle='--')\n",
    "plt.plot(fpr,tpr,marker='.',color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################### XGB classifier #####################################\n",
    "from xgboost import XGBClassifier\n",
    "XG_model = XGBClassifier(n_estimators = 200).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XG_Predictions = XG_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build confusion matrix\n",
    "# from sklearn.metrics import confusion_matrix \n",
    "# CM = confusion_matrix(y_test, y_pred)\n",
    "CM = pd.crosstab(y_test, XG_Predictions)\n",
    "\n",
    "#let us save TP, TN, FP, FN\n",
    "TN = CM.iloc[0,0]\n",
    "FN = CM.iloc[1,0]\n",
    "TP = CM.iloc[1,1]\n",
    "FP = CM.iloc[0,1]\n",
    "\n",
    "#check accuracy of model\n",
    "#accuracy_score(y_test, y_pred)*100\n",
    "print(((TP+TN)*100)/(TP+TN+FP+FN))\n",
    "\n",
    "#False Negative rate \n",
    "print((FN*100)/(FN+TP))\n",
    "\n",
    "print(\"Defaulted\", sum(XG_Predictions!=0))\n",
    "print(\"Non-defaulted \", sum(XG_Predictions==0))\n",
    "CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, XG_Predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XG_predict1 =XG_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_XG, recall_XG, thresholds_XG = precision_recall_curve(y_test,XG_predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_XG, tpr_XG, thresholds_XG = roc_curve(y_test,XG_predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC curve and AUC\n",
    "prob=XG_model.predict_proba(X_test)\n",
    "# print(prob)\n",
    "prob=prob[:,0]\n",
    "auc=roc_auc_score(y_test,prob)\n",
    "print(auc)\n",
    "fpr,tpr,thresh=roc_curve(y_test,prob)\n",
    "plt.plot([0,1],[1,0],linestyle='--')\n",
    "plt.plot(fpr,tpr,marker='.',color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "plt.plot(recall_lg, precision_lg)\n",
    "plt.plot(recall_rf, precision_rf)\n",
    "plt.plot(recall_dc, precision_dc)\n",
    "plt.plot(recall_xgb, precision_xgb)\n",
    "plt.plot(recall_XG,precision_XG)\n",
    "\n",
    "plt.legend(('Logistic Reg', 'RandomForestClassifier', 'Decision Tree','Gradient Boosting','XG Boosting'))\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision vs. Recall curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_log_reg = auc(recall_lg, precision_lg)\n",
    "print(area_log_reg)\n",
    "area_dc = auc(recall_dc, precision_dc)\n",
    "print(area_dc)\n",
    "area_rf = auc(recall_rf, precision_rf)\n",
    "print(area_rf)\n",
    "area_xgb = auc(recall_xgb, precision_xgb)\n",
    "print(area_xgb)\n",
    "area_XG = auc(recall_XG,precision_XG)\n",
    "print(area_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "plt.plot(fpr_lg, tpr_lg)\n",
    "plt.plot(fpr_dc, tpr_dc)\n",
    "plt.plot(fpr_rf, tpr_rf)\n",
    "plt.plot(fpr_xgb, tpr_xgb)\n",
    "plt.plot(fpr_XG, tpr_XG)\n",
    "plt.legend(('Logistic Regression' , 'Decision tree', 'RandomForestClassifier', 'Gradient Boosting','XG Boosting'))\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Areas_ROC_logistic  = roc_auc_score(y_test, Log_Predictions)\n",
    "Areas_ROC_decision = roc_auc_score(y_test,C50_Predictions)\n",
    "Areas_ROC_randomforest = roc_auc_score(y_test, y_best_rf_preds)\n",
    "Areas_ROC_xgb = roc_auc_score(y_test, y_predict_xgb_best)\n",
    "Areas_ROC_XG = roc_auc_score(y_test,XG_predict1)\n",
    "print(Areas_ROC_logistic)\n",
    "print(Areas_ROC_decision)\n",
    "print(Areas_ROC_randomforest)\n",
    "print(Areas_ROC_xgb)\n",
    "print(Areas_ROC_XG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving Prediction Values to local file.\n",
    "\n",
    "result=pd.DataFrame(y_test)\n",
    "result['pred_def'] = (Log_Predictions)\n",
    "\n",
    "result.to_csv(\"LG output python.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -Jointplots for Bivariate Analysis.\n",
    "# -Here Scatter plot has regression line between 2 variables along with separate Bar plots of both variables.\n",
    "plt.figure(figsize=(20,10))\n",
    "_ = sns.jointplot(x='default',y='income', data=df, kind = 'hex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship between number of age and income\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(x=df['age'], y=df['income'], s=10)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('income')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship beetween number of default and othdebt\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(x=df['default'], y=df['othdebt'], s=10)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('income')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship beetween number of employment and income\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(x=df['employ'], y=df['income'], s=10)\n",
    "plt.xlabel('employed')\n",
    "plt.ylabel('income')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
